{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __PROJET 5 - IMDB Movie Prediction__ - _*Ludovic & Yasemin*_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  __SECONDE PARTIE__ : MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#On ajoute GridSearchCV/StratifiedKFold pour l'optimisation des hyperparamètres et la validation croisée\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Pour le rééquilibrage des classes par suréchantillonnage\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>director_fb_likes</th>\n",
       "      <th>actor_1_fb_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_fb_likes</th>\n",
       "      <th>country_UK</th>\n",
       "      <th>country_USA</th>\n",
       "      <th>other_actors_fb_likes</th>\n",
       "      <th>critic_reviews_ratio</th>\n",
       "      <th>imdb_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>886204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>0.236739</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>471220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.243942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>275868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  director_fb_likes  actor_1_fb_likes        gross  \\\n",
       "0     178.0                0.0            1000.0  760505847.0   \n",
       "1     169.0              563.0           40000.0  309404152.0   \n",
       "2     148.0                0.0           11000.0  200074175.0   \n",
       "\n",
       "   num_voted_users  facenumber_in_poster       budget  title_year  \\\n",
       "0           886204                   0.0  237000000.0      2009.0   \n",
       "1           471220                   0.0  300000000.0      2007.0   \n",
       "2           275868                   1.0  245000000.0      2015.0   \n",
       "\n",
       "   aspect_ratio  movie_fb_likes  country_UK  country_USA  \\\n",
       "0          1.78           33000       False         True   \n",
       "1          2.35               0       False         True   \n",
       "2          2.35           85000        True        False   \n",
       "\n",
       "   other_actors_fb_likes  critic_reviews_ratio  imdb_classification  \n",
       "0                 1791.0              0.236739                    2  \n",
       "1                 6000.0              0.243942                    2  \n",
       "2                  554.0              0.605634                    2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chargement du dataset nettoyé\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df = pd.read_csv(\"./Datas/5000_movies_bis_clean.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4703 entries, 0 to 4702\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   duration               4703 non-null   float64\n",
      " 1   director_fb_likes      4703 non-null   float64\n",
      " 2   actor_1_fb_likes       4703 non-null   float64\n",
      " 3   gross                  4703 non-null   float64\n",
      " 4   num_voted_users        4703 non-null   int64  \n",
      " 5   facenumber_in_poster   4703 non-null   float64\n",
      " 6   budget                 4703 non-null   float64\n",
      " 7   title_year             4703 non-null   float64\n",
      " 8   aspect_ratio           4703 non-null   float64\n",
      " 9   movie_fb_likes         4703 non-null   int64  \n",
      " 10  country_UK             4703 non-null   bool   \n",
      " 11  country_USA            4703 non-null   bool   \n",
      " 12  other_actors_fb_likes  4703 non-null   float64\n",
      " 13  critic_reviews_ratio   4703 non-null   float64\n",
      " 14  imdb_classification    4703 non-null   int64  \n",
      "dtypes: bool(2), float64(10), int64(3)\n",
      "memory usage: 487.0 KB\n"
     ]
    }
   ],
   "source": [
    "#Rappel des infos actualisées de notre dataset nettoyé\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de ML : __Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7290116896918172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.64      0.46      0.53       272\n",
      "           2       0.75      0.91      0.82       597\n",
      "           3       0.89      0.39      0.54        41\n",
      "\n",
      "    accuracy                           0.73       941\n",
      "   macro avg       0.57      0.44      0.47       941\n",
      "weighted avg       0.70      0.73      0.70       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#On prépare les données pour l'entrainement\n",
    "#On supprime la variable cible\n",
    "X = df.drop([\"imdb_classification\"], axis=1)\n",
    "y = df[\"imdb_classification\"]\n",
    "\n",
    "#On divise le dataset en ensemble entrainement/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#On va maintenant pouvoir entraîner le modèle de classification RF \n",
    "#et faire des prédictions sur l'ensemble du test\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#On évalue ce que retourne le modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#Rapport détaillé de classification\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Commentaires* :\n",
    "- Ici, le modèle de classification RF prédit correctement la catégorie dans environ 73% du temps sur l'ensemble du dataset\n",
    "- Cependant, les classes ne sont pas distribuées de manière égale. En effet, les classes \"0\" et \"3\" sont mal représentées selon le rapport de classification. La classe 2 est quant à elle bien performée par le modèle, peut être même un peu trop : Faux positifs??\n",
    "\n",
    "On va tenter d'améliorer le modèle afin d'obtenir des résultats davantage satisfaisants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest : __TEST AMELIORATION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va effectuer un rééquilibrage des classes\n",
    "# avecà nbr fixe limité à 500échantillons\n",
    "X_y = pd.concat([X, y], axis=1)\n",
    "upsampled_data = pd.DataFrame()\n",
    "for class_value in X_y[\"imdb_classification\"].unique():\n",
    "    class_subset = X_y[X_y[\"imdb_classification\"] == class_value]\n",
    "    upsampled_class = resample(class_subset, replace=True, n_samples=500, random_state=42)\n",
    "    upsampled_data = pd.concat([upsampled_data, upsampled_class])\n",
    "\n",
    "#Une fois le rééquilibrage effectué, on divise de nouveau les données en ensemble entrainement/test\n",
    "X_upsampled = upsampled_data.drop(\"imdb_classification\", axis=1)\n",
    "y_upsampled = upsampled_data[\"imdb_classification\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Meilleurs paramètres: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       113\n",
      "           1       0.62      0.66      0.64        88\n",
      "           2       0.75      0.67      0.71       104\n",
      "           3       0.95      0.95      0.95        95\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.80      0.80      0.79       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Configuration des différentes combinaisons d'hyperparamètres à tester pour le modèle\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [10, 20],\n",
    "    \"min_samples_split\": [10], \n",
    "    \"min_samples_leaf\": [4]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "#Recherche sur les combinaisons spécifiées plus haut(param_grid)\n",
    "#Utilisation de la validation croisée pour évaluer chacune d'entre elles\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=cv, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "# On réentraine le modèle\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres et évaluation\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Commentaires* :\n",
    "- Avec ajout des paramètres supplémentaires, le modèle a amélioré sa performance et on obtient maintenant 80%\n",
    "- Les classes semblent être plus équilibrées, même s'il persiste encore des disparités\n",
    "- Améliorations futures : Ajouter des hyperparam supplémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/prediction_model_RF.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversion de mon modèle sous pkl pour l'app Flask\n",
    "import joblib\n",
    "joblib.dump(best_model, \"./models/prediction_model_RF.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle ML : Test avec __XGBoost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   5   1   0]\n",
      " [  5  64  19   0]\n",
      " [  5  20  73   6]\n",
      " [  0   1   0  94]]\n",
      "Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgbprd = xgb.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, xgbprd)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, xgbprd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/prediction_model_XGB.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversion de mon modèle sous pkl pour l'app Flask\n",
    "import joblib\n",
    "joblib.dump(xgb, \"./models/prediction_model_XGB.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost : __Amélioration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Meilleurs paramètres: {'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       113\n",
      "           1       0.74      0.69      0.72        88\n",
      "           2       0.82      0.77      0.79       104\n",
      "           3       0.95      0.99      0.97        95\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.86      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Configuration des différentes combinaisons d'hyperparamètres à tester pour le modèle\n",
    "param_grid = {\n",
    "    'min_child_weight': [1, 5],\n",
    "    'gamma': [0.5, 1, 2],\n",
    "    'subsample': [0.6, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "#Recherche sur les combinaisons spécifiées plus haut(param_grid)\n",
    "#Utilisation de la validation croisée pour évaluer chacune d'entre elles\n",
    "grid_search = GridSearchCV(XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic'),\n",
    "                           param_grid, cv=cv, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "# On réentraine le modèle\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres et évaluation\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/prediction_model_XGBbest.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversion de mon modèle sous pkl pour l'app Flask\n",
    "import joblib\n",
    "joblib.dump(best_model, \"./models/prediction_model_XGBbest.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
